Thank you for installing {{ .Chart.Name }}!

Your release is named {{ .Release.Name }}.

To learn more about the release, try:

  $ helm status {{ .Release.Name }} -n {{ .Release.Namespace }}
  $ helm get all {{ .Release.Name }} -n {{ .Release.Namespace }}

==============================================================================
LLM Auto Optimizer has been deployed successfully!
==============================================================================

1. Get the application URL by running these commands:
{{- if .Values.ingress.enabled }}
{{- range $host := .Values.ingress.hosts }}
  {{- range .paths }}
  HTTP:  https://{{ $host.host }}{{ .path }}
  {{- end }}
{{- end }}
{{- if .Values.ingress.grpc.enabled }}
{{- range $host := .Values.ingress.grpc.hosts }}
  {{- range .paths }}
  gRPC:  grpc://{{ $host.host }}{{ .path }}
  {{- end }}
{{- end }}
{{- end }}
{{- else if contains "NodePort" .Values.service.type }}
  export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath="{.spec.ports[0].nodePort}" services {{ include "llm-optimizer.fullname" . }}-http)
  export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath="{.items[0].status.addresses[0].address}")
  echo "HTTP:  http://$NODE_IP:$NODE_PORT"
{{- else if contains "LoadBalancer" .Values.service.type }}
  NOTE: It may take a few minutes for the LoadBalancer IP to be available.
        You can watch the status by running:
        kubectl get --namespace {{ .Release.Namespace }} svc -w {{ include "llm-optimizer.fullname" . }}-http

  export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ include "llm-optimizer.fullname" . }}-http --template "{{"{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}"}}")
  echo "HTTP:  http://$SERVICE_IP:{{ .Values.service.http.port }}"
{{- else if contains "ClusterIP" .Values.service.type }}
  export POD_NAME=$(kubectl get pods --namespace {{ .Release.Namespace }} -l "app.kubernetes.io/name={{ include "llm-optimizer.name" . }},app.kubernetes.io/instance={{ .Release.Name }}" -o jsonpath="{.items[0].metadata.name}")
  export CONTAINER_PORT=$(kubectl get pod --namespace {{ .Release.Namespace }} $POD_NAME -o jsonpath="{.spec.containers[0].ports[0].containerPort}")
  echo "Visit http://127.0.0.1:8080 to use your application"
  kubectl --namespace {{ .Release.Namespace }} port-forward $POD_NAME 8080:$CONTAINER_PORT
{{- end }}

2. Check the status of the pods:
  kubectl get pods -n {{ .Release.Namespace }} -l app.kubernetes.io/instance={{ .Release.Name }}

3. View the logs:
  kubectl logs -n {{ .Release.Namespace }} -l app.kubernetes.io/instance={{ .Release.Name }} -f

4. Access Prometheus metrics:
  kubectl port-forward -n {{ .Release.Namespace }} svc/{{ include "llm-optimizer.fullname" . }}-http 9090:9090

5. Health check endpoint:
  /health - Liveness probe
  /ready  - Readiness probe

==============================================================================
Configuration
==============================================================================

Database:
{{- if .Values.postgresql.enabled }}
  PostgreSQL (bundled): {{ include "llm-optimizer.fullname" . }}-postgresql:5432
{{- else }}
  External database configured
{{- end }}

Cache:
{{- if .Values.redis.enabled }}
  Redis (bundled): {{ include "llm-optimizer.fullname" . }}-redis-master:6379
{{- else }}
  External Redis configured
{{- end }}

Autoscaling: {{ if .Values.autoscaling.enabled }}Enabled ({{ .Values.autoscaling.minReplicas }}-{{ .Values.autoscaling.maxReplicas }} replicas){{ else }}Disabled{{ end }}

==============================================================================
Documentation
==============================================================================

For more information:
  - Documentation: https://github.com/globalbusinessadvisors/llm-auto-optimizer/tree/main/docs
  - Issues: https://github.com/globalbusinessadvisors/llm-auto-optimizer/issues
  - Homepage: https://llmdevops.dev

Happy optimizing!
